apiVersion: v1
kind: ConfigMap
metadata:
  name: flink-config
  namespace: data-platform
  labels:
    app: flink-iceberg-consumer
data:
  flink-conf.yaml: |
    # JobManager Configuration
    jobmanager.rpc.address: health-data-consumer-rest
    jobmanager.rpc.port: 6123
    jobmanager.memory.process.size: 2048m
    jobmanager.memory.flink.size: 1600m
    
    # TaskManager Configuration
    taskmanager.numberOfTaskSlots: 4
    taskmanager.memory.process.size: 4096m
    taskmanager.memory.flink.size: 3200m
    taskmanager.memory.managed.size: 1536m
    taskmanager.memory.network.min: 256m
    taskmanager.memory.network.max: 512m
    
    # Parallelism
    parallelism.default: 6
    
    # State Backend
    state.backend: rocksdb
    state.backend.incremental: true
    state.backend.rocksdb.localdir: /opt/flink/state
    
    # Checkpointing
    execution.checkpointing.mode: EXACTLY_ONCE
    execution.checkpointing.interval: 60s
    execution.checkpointing.timeout: 10min
    execution.checkpointing.min-pause: 30s
    execution.checkpointing.max-concurrent-checkpoints: 1
    execution.checkpointing.externalized-checkpoint-retention: RETAIN_ON_CANCELLATION
    state.checkpoints.dir: s3a://flink-checkpoints/health-consumer
    state.checkpoints.num-retained: 3
    
    # Savepoints
    state.savepoints.dir: s3a://flink-checkpoints/health-consumer/savepoints
    
    # Restart Strategy
    restart-strategy: fixed-delay
    restart-strategy.fixed-delay.attempts: 3
    restart-strategy.fixed-delay.delay: 10s
    
    # High Availability (optional - uncomment for production HA)
    # high-availability: kubernetes
    # high-availability.storageDir: s3a://flink-checkpoints/health-consumer/ha
    
    # Metrics
    metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.PrometheusReporter
    metrics.reporter.prom.port: 9249
    metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
    
    # Logging
    rootLogger.level: INFO
    logger.kafka.name: org.apache.kafka
    logger.kafka.level: WARN
    logger.iceberg.name: org.apache.iceberg
    logger.iceberg.level: INFO
    
    # S3 Configuration
    s3.endpoint: http://minio.data-platform.svc.cluster.local:9000
    s3.path.style.access: true
    s3.access-key: minioadmin
    s3.secret-key: minioadmin
    
    # Network Configuration
    taskmanager.network.memory.fraction: 0.1
    taskmanager.network.memory.min: 64mb
    taskmanager.network.memory.max: 1gb
    
    # Web UI
    web.submit.enable: false
    web.cancel.enable: false
    
  log4j2.properties: |
    rootLogger.level = INFO
    rootLogger.appenderRef.console.ref = ConsoleAppender
    rootLogger.appenderRef.rolling.ref = RollingFileAppender
    
    # Console appender
    appender.console.name = ConsoleAppender
    appender.console.type = CONSOLE
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
    
    # Rolling file appender
    appender.rolling.name = RollingFileAppender
    appender.rolling.type = RollingFile
    appender.rolling.fileName = ${sys:log.file}
    appender.rolling.filePattern = ${sys:log.file}.%i
    appender.rolling.layout.type = PatternLayout
    appender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
    appender.rolling.policies.type = Policies
    appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
    appender.rolling.policies.size.size = 100MB
    appender.rolling.strategy.type = DefaultRolloverStrategy
    appender.rolling.strategy.max = 10
    
    # Suppress noisy loggers
    logger.kafka.name = org.apache.kafka
    logger.kafka.level = WARN
    logger.zookeeper.name = org.apache.zookeeper
    logger.zookeeper.level = WARN
    logger.netty.name = org.apache.flink.shaded.netty4
    logger.netty.level = WARN
